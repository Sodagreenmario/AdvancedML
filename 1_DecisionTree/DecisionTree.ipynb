{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My DecisionTree\n",
    "class Node():\n",
    "    \"\"\"\n",
    "        A Node in the decision tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        value : double, default=None\n",
    "            The possible value.\n",
    "            \n",
    "        best_feat : int, default=None\n",
    "            The best feature to split in the current node.\n",
    "            \n",
    "        best_thr : double, default=None\n",
    "            The best threshold of the best feature.\n",
    "            \n",
    "        leaf_branch : Node, default=None\n",
    "            The left branch of the current node.\n",
    "            \n",
    "        right_branch : Node, default=None\n",
    "            The right branch of the current node.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, best_feat, best_thr, left_branch, right_branch):\n",
    "        self.value = value\n",
    "        self.best_feat = best_feat\n",
    "        self.best_thr = best_thr\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch\n",
    "\n",
    "class DecisionTree():\n",
    "    \"\"\"\n",
    "        A classifier based on decision tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        criterion : {'id3', 'c45'}, default='id3'\n",
    "            The criterion function to measure the quality of a split.\n",
    "        \n",
    "        max_depth : int, default=None\n",
    "            The maximum depth of the tree.\n",
    "            \n",
    "        min_sample_leaf : int, default=None\n",
    "            The minimum numbers of samples required to be at a leaf node.\n",
    "            \n",
    "        min_impurity_split : double, default=None\n",
    "            Threshold for early stopping in tree growth.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, criterion='id3', max_depth=None, \\\n",
    "                 min_sample_leaf=4, min_impurity_split=1e-7):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = (np.iinfo(np.int32).max if max_depth is None else max_depth)\n",
    "        self.min_sample_leaf = min_sample_leaf\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        self.root = None\n",
    "        \n",
    "    def __entropy__(self, x):\n",
    "        \"\"\"\n",
    "            Calculate the entropy.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            H : double\n",
    "                The entropy of x.\n",
    "        \"\"\"\n",
    "        D = x.shape[0]\n",
    "        H = 0\n",
    "        for k in np.unique(x):\n",
    "            Ck = len(x[x == k])\n",
    "            H += - (Ck / D) * np.log2(Ck / D)\n",
    "        return H\n",
    "    \n",
    "    def __gini__(self, x):\n",
    "        \"\"\"\n",
    "            Calculate the gini coefficient.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            G : double\n",
    "                The gini coeeficient of x.\n",
    "        \"\"\"\n",
    "        D = x.shape[0]\n",
    "        G = 0\n",
    "        for k in np.unique(x):\n",
    "            Ck = len(x[x == k])\n",
    "            G += (Ck / D) ** 2\n",
    "        G = 1 - G\n",
    "        return G\n",
    "    \n",
    "    def __id3__(self, y, yl, yr):\n",
    "        \"\"\"\n",
    "            Information gain.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : double\n",
    "              \n",
    "        \"\"\"\n",
    "        D, Dl, Dr = len(y), len(yl), len(yr)\n",
    "        H_D = self.__entropy__(y)\n",
    "        H_Dl = Dl / D * self.__entropy__(yl)\n",
    "        H_Dr = Dr / D * self.__entropy__(yr)\n",
    "        return H_D - (H_Dl + H_Dr)\n",
    "    \n",
    "    def __c45__(self, y, yl, yr):\n",
    "        \"\"\"\n",
    "            Information gain ratio.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : double\n",
    "        \"\"\"\n",
    "        D, Dl, Dr = len(y), len(yl), len(yr)\n",
    "        H_D = self.__entropy__(y)\n",
    "        H_Dl = Dl / D * self.__entropy__(yl)\n",
    "        H_Dr = Dr / D * self.__entropy__(yr)\n",
    "        return (H_D - (H_Dl + H_Dr)) / H_D\n",
    "    \n",
    "    def __cart__(self, y, yl, yr):\n",
    "        \"\"\"\n",
    "            Gini coefficient.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : double\n",
    "        \"\"\"\n",
    "        D, Dl, Dr = len(y), len(yl), len(yr)\n",
    "        G_Dl = Dl / D * self.__gini__(yl)\n",
    "        G_Dr = Dr / D * self.__gini__(yr)\n",
    "        # To get minimum gini, add negative symbol\n",
    "        return - (G_Dl + G_Dr)\n",
    "    \n",
    "    def __criterion__(self, y, yl, yr):\n",
    "        \"\"\"\n",
    "            Choose one of the criterion function to measure the split.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : double \n",
    "        \"\"\"\n",
    "        if self.criterion == 'id3':\n",
    "            return self.__id3__(y, yl, yr)\n",
    "        elif self.criterion == 'c45':\n",
    "            return self.__c45__(y, yl, yr)\n",
    "        else:\n",
    "            raise ValueError('The criterion should be one of [\\'id3\\', \\'c45\\'].')\n",
    "            \n",
    "    def __getThr__(self, feature):\n",
    "        \"\"\"\n",
    "            Get the initialized thresholds of a feature.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : list\n",
    "        \"\"\"\n",
    "        t = sorted(feature)\n",
    "        return [(t[i] + t[i-1]) / 2 for i in range(1, len(t))]\n",
    "    \n",
    "    def __getSplit__(self, X, y, feat_ind, thr):\n",
    "        \"\"\"\n",
    "            Get the split of X and y.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : tuple of list\n",
    "        \"\"\"\n",
    "        t = X[:, feat_ind] < thr\n",
    "        return X[t], y[t], X[~t], y[~t]\n",
    "        \n",
    "    def __build__(self, X, y, depth):\n",
    "        \"\"\"\n",
    "            Build the decision tree.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              node : Node\n",
    "        \"\"\"\n",
    "        node = Node(None, None, None, None, None)\n",
    "        row, col = X.shape\n",
    "        \n",
    "        if depth <= self.max_depth and row > self.min_sample_leaf:\n",
    "            # Find the best feature to split\n",
    "            bfeat_ind = None\n",
    "            bfeat_gain = np.iinfo(np.int32).min\n",
    "            bfeat_thr = None\n",
    "            for feat_ind in range(col):\n",
    "                thresholds = self.__getThr__(X[:, feat_ind])\n",
    "                for thr in thresholds:\n",
    "                    X1, y1, X2, y2 = self.__getSplit__(X, y, feat_ind, thr)\n",
    "                    gain = self.__criterion__(y, y1, y2)\n",
    "                    if gain >= bfeat_gain:\n",
    "                        bfeat_gain = gain\n",
    "                        bfeat_thr = thr\n",
    "                        bfeat_ind = feat_ind\n",
    "                        \n",
    "            if bfeat_gain > self.min_impurity_split:\n",
    "                # Continue splitting\n",
    "                X1, y1, X2, y2 = self.__getSplit__(X, y, bfeat_ind, bfeat_thr)\n",
    "                node.best_thr = bfeat_thr\n",
    "                node.best_feat = bfeat_ind\n",
    "                node.value = None\n",
    "                del X\n",
    "                node.left_branch = self.__build__(X1, y1, depth + 1)\n",
    "                node.right_branch = self.__build__(X2, y2, depth + 1)\n",
    "            else:\n",
    "                # Stop splitting\n",
    "                del X\n",
    "                node.value = np.argmax(np.bincount(y.flatten()))\n",
    "            return node\n",
    "        else:\n",
    "            del X\n",
    "            node.value = np.argmax(np.bincount(y.flatten()))\n",
    "            return node\n",
    "    \n",
    "    def __find__(self, x, node):\n",
    "        \"\"\"\n",
    "            Find the potential predicted label in the decision tree.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "              : int\n",
    "        \"\"\"\n",
    "        if node.value is None:\n",
    "            if x[node.best_feat] < node.best_thr:\n",
    "                return self.__find__(x, node.left_branch)\n",
    "            else:\n",
    "                return self.__find__(x, node.right_branch)\n",
    "        else:\n",
    "            return node.value\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray)\n",
    "        if y.ndim == 1:\n",
    "            y = np.reshape(y, (-1, 1))\n",
    "        # Build tree\n",
    "        self.root = self.__build__(X, y, 0)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        assert isinstance(X, np.ndarray)\n",
    "        y = []\n",
    "        for x in X:\n",
    "            y.append(self.__find__(x, self.root))\n",
    "        return np.array(y)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray)\n",
    "        pred = self.predict(X)\n",
    "        return (pred == y).sum() / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help function\n",
    "def evaluate_tree(clf, kfold):\n",
    "    results = []\n",
    "    train_time = []\n",
    "    test_time = []\n",
    "    for train_idx, test_idx in kf.split(data.data):\n",
    "        X_train, y_train = data.data[train_idx], data.target[train_idx]\n",
    "        X_test, y_test = data.data[test_idx], data.target[test_idx]\n",
    "        t1 = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        t2 = time.time()\n",
    "        train_time.append(t2 - t1)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        test_time.append(time.time() - t2)\n",
    "        results.append(score)\n",
    "    return results, train_time, test_time\n",
    "\n",
    "def avg_performance(x):\n",
    "    assert isinstance(x, list)\n",
    "    return np.average(np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "kf = KFold(n_splits=5, random_state=2020, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn built-in DecisionTreeClassifier\n",
    "clf1 = DecisionTreeClassifier(random_state=508)\n",
    "builtin_results, builtin_train_time, builtin_test_time = evaluate_tree(clf1, kf)\n",
    "# My DecisionTreeClassifier\n",
    "clf2 = DecisionTree('id3')\n",
    "my_results, my_train_time, my_test_time = evaluate_tree(clf2, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn built-in DecisionTreeClassfier v.s. My DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Accuracy(%)|  Fold1  |  Fold2  |  Fold3  |  Fold4  |  Fold5  |  Avg.  |\n",
    "|:----------|:-------:|:-------:|:-------:|:-------:|:-------:|:------:|\n",
    "|Built-in   |  92.98  |  95.61  |  91.22  |  96.49  |  92.92  |  93.85 |\n",
    "|Mine       |  93.86  |  95.61  |  92.98  |  94.73  |  95.57  |  94.55 |\n",
    "\n",
    "|Train time(s)|  Fold1  |  Fold2  |  Fold3  |  Fold4  |  Fold5  |  Avg.  |\n",
    "|:------------|:-------:|:-------:|:-------:|:-------:|:-------:|:------:|\n",
    "|Built-in     |  0.0081 |  0.0069 |  0.0064 |  0.0062 |  0.0080 | 0.0071 |\n",
    "|Mine         |  4.9146 |  5.5333 |  5.1658 |  5.1595 |  5.2357 | 5.2018 |\n",
    "\n",
    "|Test time(ms)|  Fold1  |  Fold2  |  Fold3  |  Fold4  |  Fold5  |  Avg.  |\n",
    "|:------------|:-------:|:-------:|:-------:|:-------:|:-------:|:------:|\n",
    "|Built-in     |  0.4890 |  0.6101 |  0.3319 |  0.2789 |  0.3757 | 0.4171 |\n",
    "|Mine         |  0.2398 |  0.2649 |  0.2441 |  0.2868 |  0.2698 | 0.2611 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
